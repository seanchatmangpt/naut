{
    "sourceFile": "download_binance_orderbook.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1749259122209,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1749259166948,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,84 @@\n+import os\n+import pandas as pd\n+from pathlib import Path\n+from datetime import datetime\n+import requests\n+import gzip\n+import io\n+\n+def download_binance_orderbook(symbol: str, date: str, output_dir: str):\n+    \"\"\"\n+    Download Binance orderbook data for a specific date using their official AWS S3 data.\n+    \n+    Args:\n+        symbol: Trading pair symbol (e.g., 'BTCUSDT')\n+        date: Date in YYYY-MM-DD format\n+        output_dir: Directory to save the files\n+    \"\"\"\n+    # Create output directory if it doesn't exist\n+    output_path = Path(output_dir).expanduser() / \"Data\" / \"Binance\"\n+    output_path.mkdir(parents=True, exist_ok=True)\n+    \n+    # Convert date to Binance's format (YYYY-MM-DD)\n+    date_obj = datetime.strptime(date, \"%Y-%m-%d\")\n+    date_str = date_obj.strftime(\"%Y-%m-%d\")\n+    \n+    # Base URL for Binance's AWS S3 data\n+    base_url = \"https://data.binance.vision/data/spot/daily/depth\"\n+    \n+    # File patterns for the data we need\n+    files = [\n+        f\"{symbol}-depth-snapshots-{date_str}.zip\",  # Orderbook snapshots\n+        f\"{symbol}-depth-{date_str}.zip\",  # Orderbook updates\n+    ]\n+    \n+    for file in files:\n+        url = f\"{base_url}/{symbol}/{file}\"\n+        print(f\"\\nDownloading {file}...\")\n+        \n+        try:\n+            # Download the file\n+            response = requests.get(url)\n+            response.raise_for_status()\n+            \n+            # Save the file\n+            file_path = output_path / file\n+            with open(file_path, 'wb') as f:\n+                f.write(response.content)\n+            \n+            print(f\"Successfully downloaded {file}\")\n+            \n+            # Process the file based on its type\n+            if \"snapshots\" in file:\n+                # Process snapshots\n+                df = pd.read_csv(file_path, compression='zip')\n+                output_file = output_path / f\"{symbol}_T_DEPTH_{date}_depth_snap.csv\"\n+                df.to_csv(output_file, index=False)\n+                print(f\"Processed snapshots saved to {output_file}\")\n+            else:\n+                # Process updates\n+                df = pd.read_csv(file_path, compression='zip')\n+                output_file = output_path / f\"{symbol}_T_DEPTH_{date}_depth_update.csv\"\n+                df.to_csv(output_file, index=False)\n+                print(f\"Processed updates saved to {output_file}\")\n+            \n+            # Clean up the zip file\n+            os.remove(file_path)\n+            \n+        except requests.exceptions.HTTPError as e:\n+            if e.response.status_code == 404:\n+                print(f\"File not found: {file}\")\n+            else:\n+                print(f\"Error downloading {file}: {e}\")\n+        except Exception as e:\n+            print(f\"Error processing {file}: {e}\")\n+    \n+    print(f\"\\nDownload complete! Files saved to {output_path}\")\n+\n+if __name__ == \"__main__\":\n+    # Download BTCUSDT orderbook data for November 1st, 2022\n+    download_binance_orderbook(\n+        symbol=\"BTCUSDT\",\n+        date=\"2022-11-01\",\n+        output_dir=\"~/Downloads\"\n+    ) \n\\ No newline at end of file\n"
                }
            ],
            "date": 1749259122209,
            "name": "Commit-0",
            "content": "import os\nimport time\nfrom datetime import datetime, timedelta\nimport requests\nimport pandas as pd\nfrom pathlib import Path\n\ndef download_binance_orderbook(symbol: str, date: str, output_dir: str):\n    \"\"\"\n    Download Binance orderbook data for a specific date.\n    \n    Args:\n        symbol: Trading pair symbol (e.g., 'BTCUSDT')\n        date: Date in YYYY-MM-DD format\n        output_dir: Directory to save the files\n    \"\"\"\n    # Create output directory if it doesn't exist\n    output_path = Path(output_dir).expanduser() / \"Data\" / \"Binance\"\n    output_path.mkdir(parents=True, exist_ok=True)\n    \n    # Convert date string to timestamp\n    start_time = int(datetime.strptime(date, \"%Y-%m-%d\").timestamp() * 1000)\n    end_time = int((datetime.strptime(date, \"%Y-%m-%d\") + timedelta(days=1)).timestamp() * 1000)\n    \n    # Download orderbook snapshots\n    print(f\"Downloading orderbook snapshots for {symbol} on {date}...\")\n    snapshots = []\n    current_time = start_time\n    \n    while current_time < end_time:\n        try:\n            # Get orderbook snapshot\n            url = f\"https://api.binance.com/api/v3/depth?symbol={symbol}&limit=5000\"\n            response = requests.get(url)\n            response.raise_for_status()\n            snapshot = response.json()\n            \n            # Add timestamp\n            snapshot['timestamp'] = current_time\n            snapshots.append(snapshot)\n            \n            # Save snapshot to CSV\n            snapshot_file = output_path / f\"{symbol}_T_DEPTH_{date}_depth_snap.csv\"\n            pd.DataFrame([{\n                'timestamp': current_time,\n                'bids': str(snapshot['bids']),\n                'asks': str(snapshot['asks']),\n            }]).to_csv(snapshot_file, index=False)\n            \n            print(f\"Saved snapshot at {datetime.fromtimestamp(current_time/1000)}\")\n            \n            # Wait 1 second before next snapshot (respect rate limits)\n            time.sleep(1)\n            current_time += 1000  # Move forward 1 second\n            \n        except Exception as e:\n            print(f\"Error downloading snapshot: {e}\")\n            time.sleep(5)  # Wait longer on error\n            continue\n    \n    # Download orderbook updates (trades)\n    print(f\"\\nDownloading orderbook updates for {symbol} on {date}...\")\n    trades = []\n    current_time = start_time\n    \n    while current_time < end_time:\n        try:\n            # Get trades\n            url = f\"https://api.binance.com/api/v3/aggTrades?symbol={symbol}&startTime={current_time}&endTime={current_time + 3600000}&limit=1000\"\n            response = requests.get(url)\n            response.raise_for_status()\n            trade_data = response.json()\n            \n            if trade_data:\n                trades.extend(trade_data)\n                print(f\"Downloaded {len(trade_data)} trades at {datetime.fromtimestamp(current_time/1000)}\")\n            \n            # Save trades to CSV\n            if trades:\n                trades_file = output_path / f\"{symbol}_T_DEPTH_{date}_depth_update.csv\"\n                pd.DataFrame(trades).to_csv(trades_file, index=False)\n            \n            current_time += 3600000  # Move forward 1 hour\n            \n        except Exception as e:\n            print(f\"Error downloading trades: {e}\")\n            time.sleep(5)  # Wait longer on error\n            continue\n    \n    print(f\"\\nDownload complete! Files saved to {output_path}\")\n\nif __name__ == \"__main__\":\n    # Download BTCUSDT orderbook data for November 1st, 2022\n    download_binance_orderbook(\n        symbol=\"BTCUSDT\",\n        date=\"2022-11-01\",\n        output_dir=\"~/Downloads\"\n    ) "
        }
    ]
}